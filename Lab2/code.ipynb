{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f7a1881-1da9-4d72-8a47-5b7817640b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded.\n",
      "graph(%self.1 : __torch__.torch.nn.modules.module.___torch_mangle_359.Module,\n",
      "      %input.1 : Float(20, 3, 224, 224)):\n",
      "  %196 : __torch__.torch.nn.modules.module.___torch_mangle_358.Module = prim::GetAttr[name=\"classifier\"](%self.1)\n",
      "  %187 : __torch__.torch.nn.modules.module.___torch_mangle_353.Module = prim::GetAttr[name=\"features\"](%self.1)\n",
      "  %212 : Tensor = prim::CallMethod[name=\"forward\"](%187, %input.1)\n",
      "  %142 : int = prim::Constant[value=1]() # /tmp/ipykernel_883/148130232.py:195:0\n",
      "  %143 : int = prim::Constant[value=-1]() # /tmp/ipykernel_883/148130232.py:195:0\n",
      "  %input.10 : Float(20, 4608) = aten::flatten(%212, %142, %143) # /tmp/ipykernel_883/148130232.py:195:0\n",
      "  %213 : Tensor = prim::CallMethod[name=\"forward\"](%196, %input.10)\n",
      "  return (%213)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/PyTorch-1.4/lib/python3.7/site-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type AlexNet_2. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 \tTrain Loss: 4.296320 \tValidation Loss: 4.214108 \tValidation Top1 Accuracy: 14.05% \n",
      "Validation Top5 Accuracy: 30.09%\n",
      "Epoch:  2 \tTrain Loss: 3.843490 \tValidation Loss: 3.549787 \tValidation Top1 Accuracy: 25.11% \n",
      "Validation Top5 Accuracy: 37.28%\n",
      "Epoch:  3 \tTrain Loss: 3.103064 \tValidation Loss: 2.954982 \tValidation Top1 Accuracy: 35.84% \n",
      "Validation Top5 Accuracy: 52.77%\n",
      "Epoch:  4 \tTrain Loss: 2.542129 \tValidation Loss: 2.488135 \tValidation Top1 Accuracy: 43.69% \n",
      "Validation Top5 Accuracy: 62.94%\n",
      "Epoch:  5 \tTrain Loss: 2.062861 \tValidation Loss: 2.207846 \tValidation Top1 Accuracy: 49.23% \n",
      "Validation Top5 Accuracy: 67.48%\n",
      "Epoch:  6 \tTrain Loss: 1.712056 \tValidation Loss: 2.222185 \tValidation Top1 Accuracy: 51.22% \n",
      "Validation Top5 Accuracy: 69.25%\n",
      "Epoch:  7 \tTrain Loss: 1.486735 \tValidation Loss: 2.046207 \tValidation Top1 Accuracy: 53.54% \n",
      "Validation Top5 Accuracy: 72.46%\n",
      "Epoch:  8 \tTrain Loss: 1.232423 \tValidation Loss: 2.003794 \tValidation Top1 Accuracy: 57.30% \n",
      "Validation Top5 Accuracy: 74.00%\n",
      "Epoch:  9 \tTrain Loss: 1.000860 \tValidation Loss: 2.016453 \tValidation Top1 Accuracy: 56.19% \n",
      "Validation Top5 Accuracy: 76.88%\n",
      "Epoch:  10 \tTrain Loss: 0.831060 \tValidation Loss: 1.953129 \tValidation Top1 Accuracy: 59.73% \n",
      "Validation Top5 Accuracy: 76.44%\n",
      "Epoch:  11 \tTrain Loss: 0.696168 \tValidation Loss: 2.156409 \tValidation Top1 Accuracy: 58.52% \n",
      "Validation Top5 Accuracy: 76.00%\n",
      "Epoch:  12 \tTrain Loss: 0.553109 \tValidation Loss: 2.159843 \tValidation Top1 Accuracy: 59.18% \n",
      "Validation Top5 Accuracy: 77.88%\n",
      "Epoch:  13 \tTrain Loss: 0.427501 \tValidation Loss: 2.239644 \tValidation Top1 Accuracy: 58.63% \n",
      "Validation Top5 Accuracy: 78.87%\n",
      "Epoch:  14 \tTrain Loss: 0.330800 \tValidation Loss: 2.447720 \tValidation Top1 Accuracy: 59.40% \n",
      "Validation Top5 Accuracy: 78.21%\n",
      "Epoch:  15 \tTrain Loss: 0.294175 \tValidation Loss: 2.467567 \tValidation Top1 Accuracy: 59.85% \n",
      "Validation Top5 Accuracy: 78.43%\n",
      "Epoch:  16 \tTrain Loss: 0.259309 \tValidation Loss: 2.540552 \tValidation Top1 Accuracy: 59.96% \n",
      "Validation Top5 Accuracy: 77.88%\n",
      "Epoch:  17 \tTrain Loss: 0.223053 \tValidation Loss: 2.681532 \tValidation Top1 Accuracy: 60.07% \n",
      "Validation Top5 Accuracy: 76.77%\n",
      "Epoch:  18 \tTrain Loss: 0.171155 \tValidation Loss: 2.954108 \tValidation Top1 Accuracy: 59.96% \n",
      "Validation Top5 Accuracy: 78.98%\n",
      "Epoch:  19 \tTrain Loss: 0.160504 \tValidation Loss: 2.830042 \tValidation Top1 Accuracy: 60.51% \n",
      "Validation Top5 Accuracy: 78.98%\n",
      "Epoch:  20 \tTrain Loss: 0.153387 \tValidation Loss: 2.768252 \tValidation Top1 Accuracy: 61.73% \n",
      "Validation Top5 Accuracy: 78.65%\n",
      "Epoch:  21 \tTrain Loss: 0.138194 \tValidation Loss: 3.081535 \tValidation Top1 Accuracy: 60.84% \n",
      "Validation Top5 Accuracy: 79.31%\n",
      "Epoch:  22 \tTrain Loss: 0.120789 \tValidation Loss: 3.166608 \tValidation Top1 Accuracy: 60.51% \n",
      "Validation Top5 Accuracy: 79.65%\n",
      "Epoch:  23 \tTrain Loss: 0.101732 \tValidation Loss: 3.150156 \tValidation Top1 Accuracy: 60.40% \n",
      "Validation Top5 Accuracy: 77.99%\n",
      "Epoch:  24 \tTrain Loss: 0.102266 \tValidation Loss: 3.024319 \tValidation Top1 Accuracy: 60.73% \n",
      "Validation Top5 Accuracy: 78.54%\n",
      "Epoch:  25 \tTrain Loss: 0.118552 \tValidation Loss: 2.955588 \tValidation Top1 Accuracy: 61.73% \n",
      "Validation Top5 Accuracy: 79.54%\n",
      "Epoch:  26 \tTrain Loss: 0.097006 \tValidation Loss: 3.226692 \tValidation Top1 Accuracy: 61.28% \n",
      "Validation Top5 Accuracy: 78.76%\n",
      "Epoch:  27 \tTrain Loss: 0.096444 \tValidation Loss: 3.075147 \tValidation Top1 Accuracy: 62.06% \n",
      "Validation Top5 Accuracy: 78.98%\n",
      "Epoch:  28 \tTrain Loss: 0.076083 \tValidation Loss: 3.406909 \tValidation Top1 Accuracy: 60.84% \n",
      "Validation Top5 Accuracy: 78.21%\n",
      "Epoch:  29 \tTrain Loss: 0.063731 \tValidation Loss: 3.234313 \tValidation Top1 Accuracy: 60.95% \n",
      "Validation Top5 Accuracy: 78.32%\n",
      "Epoch:  30 \tTrain Loss: 0.091359 \tValidation Loss: 3.319638 \tValidation Top1 Accuracy: 61.73% \n",
      "Validation Top5 Accuracy: 79.87%\n",
      "Epoch:  31 \tTrain Loss: 0.087372 \tValidation Loss: 3.138731 \tValidation Top1 Accuracy: 62.94% \n",
      "Validation Top5 Accuracy: 79.54%\n",
      "Epoch:  32 \tTrain Loss: 0.055131 \tValidation Loss: 3.456784 \tValidation Top1 Accuracy: 61.95% \n",
      "Validation Top5 Accuracy: 78.43%\n",
      "Epoch:  33 \tTrain Loss: 0.048315 \tValidation Loss: 3.488240 \tValidation Top1 Accuracy: 60.73% \n",
      "Validation Top5 Accuracy: 78.76%\n",
      "Epoch:  34 \tTrain Loss: 0.084406 \tValidation Loss: 3.236081 \tValidation Top1 Accuracy: 60.95% \n",
      "Validation Top5 Accuracy: 79.09%\n",
      "Epoch:  35 \tTrain Loss: 0.077986 \tValidation Loss: 3.324096 \tValidation Top1 Accuracy: 61.95% \n",
      "Validation Top5 Accuracy: 78.87%\n",
      "Epoch:  36 \tTrain Loss: 0.065190 \tValidation Loss: 3.275988 \tValidation Top1 Accuracy: 63.05% \n",
      "Validation Top5 Accuracy: 78.65%\n",
      "Epoch:  37 \tTrain Loss: 0.063062 \tValidation Loss: 3.281851 \tValidation Top1 Accuracy: 58.96% \n",
      "Validation Top5 Accuracy: 79.31%\n",
      "Epoch:  38 \tTrain Loss: 0.060339 \tValidation Loss: 3.321651 \tValidation Top1 Accuracy: 64.38% \n",
      "Validation Top5 Accuracy: 79.98%\n",
      "Epoch:  39 \tTrain Loss: 0.059462 \tValidation Loss: 3.436021 \tValidation Top1 Accuracy: 62.61% \n",
      "Validation Top5 Accuracy: 78.87%\n",
      "Epoch:  40 \tTrain Loss: 0.054117 \tValidation Loss: 3.474848 \tValidation Top1 Accuracy: 61.39% \n",
      "Validation Top5 Accuracy: 78.98%\n",
      "Epoch:  41 \tTrain Loss: 0.051345 \tValidation Loss: 3.488765 \tValidation Top1 Accuracy: 63.50% \n",
      "Validation Top5 Accuracy: 78.87%\n",
      "Epoch:  42 \tTrain Loss: 0.056377 \tValidation Loss: 3.819450 \tValidation Top1 Accuracy: 60.62% \n",
      "Validation Top5 Accuracy: 77.32%\n",
      "Epoch:  43 \tTrain Loss: 0.070228 \tValidation Loss: 3.458258 \tValidation Top1 Accuracy: 61.50% \n",
      "Validation Top5 Accuracy: 78.21%\n",
      "Epoch:  44 \tTrain Loss: 0.059963 \tValidation Loss: 3.352670 \tValidation Top1 Accuracy: 61.62% \n",
      "Validation Top5 Accuracy: 79.09%\n",
      "Epoch:  45 \tTrain Loss: 0.052580 \tValidation Loss: 3.230024 \tValidation Top1 Accuracy: 61.39% \n",
      "Validation Top5 Accuracy: 80.53%\n",
      "Epoch:  46 \tTrain Loss: 0.045036 \tValidation Loss: 3.552440 \tValidation Top1 Accuracy: 62.17% \n",
      "Validation Top5 Accuracy: 79.42%\n",
      "Epoch:  47 \tTrain Loss: 0.043613 \tValidation Loss: 3.758495 \tValidation Top1 Accuracy: 61.17% \n",
      "Validation Top5 Accuracy: 78.98%\n",
      "Epoch:  48 \tTrain Loss: 0.042604 \tValidation Loss: 3.748059 \tValidation Top1 Accuracy: 62.72% \n",
      "Validation Top5 Accuracy: 81.19%\n",
      "Epoch:  49 \tTrain Loss: 0.041744 \tValidation Loss: 3.801348 \tValidation Top1 Accuracy: 60.18% \n",
      "Validation Top5 Accuracy: 78.54%\n",
      "Epoch:  50 \tTrain Loss: 0.054410 \tValidation Loss: 3.658762 \tValidation Top1 Accuracy: 60.29% \n",
      "Validation Top5 Accuracy: 78.76%\n",
      "Save tensornoard.\n",
      "Test Loss: 3.284501 \tTesting Accuracy: 63.78% \tTesting Top5 Accuracy: 81.45%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "from PIL import Image\n",
    "import torch\n",
    "torch.set_printoptions(profile=\"default\")\n",
    "from torch import nn, optim\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch.autograd import Variable\n",
    "\n",
    "parser = argparse.ArgumentParser('Caltech101_AlexNet')\n",
    "parser.add_argument('--ObjectCategories_dir', type=str, default='101_ObjectCategories')\n",
    "parser.add_argument('--seed', type=int, default=20) # 数据集划分随机种子\n",
    "parser.add_argument('--batch_size', type=int, default=10)\n",
    "parser.add_argument('--img_size', type=int, default=224) # 通过序号选择用哪一个多层感知，用来对比效果\n",
    "parser.add_argument('--nn', type=str, default='0') # 通过序号选择用哪一个神经网络，用来对比效果\n",
    "parser.add_argument('--gpu', type=int, default=0) # -1时为CPU\n",
    "parser.add_argument('--niters', type=int, default=50) # 训练的epoch数\n",
    "parser.add_argument('--model_dir', type=str, default='./model/AlexNet.pth') # 最佳模型存储路径\n",
    "parser.add_argument('--tensorboard_dir', type=str, default='')\n",
    "args = parser.parse_args(args=['--batch_size', '256', '--niters', '50', '--nn', '2', '--tensorboard_dir', ''])\n",
    "\n",
    "device = torch.device('cpu' if args.gpu == -1 else 'cuda:' + str(args.gpu))\n",
    "\n",
    "\n",
    "class Caltech101Dataset(Dataset):\n",
    "    def __init__(self, args, split='train'):\n",
    "        data_dir = args.ObjectCategories_dir\n",
    "        categories = os.listdir(data_dir)\n",
    "        categories.remove('BACKGROUND_Google')\n",
    "        \n",
    "        self.transforms = transforms.Compose([\n",
    "            transforms.Resize((args.img_size, args.img_size)),\n",
    "            transforms.ToTensor(),])\n",
    "        \n",
    "        X_train, y_train, X_val, y_val, X_test, y_test = [], [], [], [], [], []\n",
    "        \n",
    "        for i, cat in enumerate(categories):\n",
    "            cat_dir = os.path.join(data_dir, cat)\n",
    "            X = []\n",
    "            y = []\n",
    "            for file in os.listdir(cat_dir):\n",
    "                img_path = os.path.join(cat_dir, file)\n",
    "                img = self.transforms(Image.open(img_path).convert('RGB'))\n",
    "                X.append(img)\n",
    "                y.append(i)\n",
    "            \n",
    "            # stratify=y 表示在分割数据时要保持标签 y 的比例，这意味着训练集和测试集中每个类别的样本比例与原始数据集中相同。\n",
    "            X_train_val, X_test_cat, y_train_val, y_test_cat = train_test_split(X, y, test_size=0.1, \n",
    "                                                                                stratify=y, random_state=args.seed)\n",
    "            X_train_cat, X_val_cat, y_train_cat, y_val_cat = train_test_split(X_train_val, y_train_val, \n",
    "                                                                              test_size=0.1111, stratify=y_train_val, \n",
    "                                                                              random_state=args.seed)\n",
    "            \n",
    "            X_train.extend(X_train_cat) # X_train_cat 中的所有元素都将被添加到 X_train 列表的末尾\n",
    "            y_train.extend(y_train_cat)\n",
    "            X_val.extend(X_val_cat)\n",
    "            y_val.extend(y_val_cat)\n",
    "            X_test.extend(X_test_cat)\n",
    "            y_test.extend(y_test_cat)\n",
    "\n",
    "        if split == 'train':\n",
    "            self.X = X_train\n",
    "            self.y = y_train\n",
    "        elif split == 'val':\n",
    "            self.X = X_val\n",
    "            self.y = y_val\n",
    "        elif split == 'test':\n",
    "            self.X = X_test\n",
    "            self.y = y_test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "  \n",
    "\n",
    "class AlexNet_0(nn.Module):\n",
    "    def __init__(self, num_classes=101, init_weights=True):   \n",
    "        super(AlexNet_0, self).__init__()\n",
    "        self.features = nn.Sequential(  #打包\n",
    "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=2),  # input[3, 224, 224]  output[96, 55, 55] \n",
    "            nn.ReLU(inplace=True), #inplace 可以载入更大模型\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),                  # output[96, 27, 27] \n",
    "            nn.Conv2d(96, 256, kernel_size=5, padding=2),           # output[256, 27, 27]\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),                  # output[256, 13, 13]\n",
    "            nn.Conv2d(256, 384, kernel_size=3, padding=1),          # output[256, 13, 13]\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 384, kernel_size=3, padding=1),          # output[384, 13, 13]\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),          # output[256, 13, 13]\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),                  # output[128, 6, 6]\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            #全连接\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, start_dim=1) #展平   或者view()\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu') #何教授方法\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)  #正态分布赋值\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "class AlexNet_1(nn.Module):\n",
    "    def __init__(self, num_classes=101, init_weights=True):   \n",
    "        super(AlexNet_1, self).__init__()\n",
    "        self.features = nn.Sequential(  #打包\n",
    "            nn.Conv2d(3, 48, kernel_size=11, stride=4, padding=2),  # input[3, 224, 224]  output[48, 55, 55] 自动舍去小数点后\n",
    "            nn.ReLU(inplace=True), #inplace 可以载入更大模型\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),                  # output[48, 27, 27] kernel_num为原论文一半\n",
    "            nn.Conv2d(48, 128, kernel_size=5, padding=2),           # output[128, 27, 27]\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),                  # output[128, 13, 13]\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),          # output[128, 13, 13]\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),                  # output[128, 6, 6]\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            #全链接\n",
    "            nn.Linear(128 * 6 * 6, 2048),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(2048, num_classes),\n",
    "        )\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, start_dim=1) #展平   或者view()\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu') #何教授方法\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)  #正态分布赋值\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "class AlexNet_2(nn.Module):\n",
    "    def __init__(self, num_classes=101, init_weights=True):   \n",
    "        super(AlexNet_2, self).__init__()\n",
    "        self.features = nn.Sequential(  #打包\n",
    "            nn.Conv2d(3, 48, kernel_size=11, stride=4, padding=2),  # input[3, 224, 224]  output[48, 55, 55] 自动舍去小数点后\n",
    "            nn.ReLU(inplace=True), #inplace 可以载入更大模型\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),                  # output[48, 27, 27] kernel_num为原论文一半\n",
    "            nn.Conv2d(48, 128, kernel_size=5, padding=2),           # output[128, 27, 27]\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),                  # output[128, 13, 13]\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),          # output[128, 13, 13]\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),                  # output[128, 6, 6]\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            #全链接\n",
    "            nn.Linear(128 * 6 * 6, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, num_classes),\n",
    "        )\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, start_dim=1) #展平   或者view()\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu') #何教授方法\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)  #正态分布赋值\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "class AlexNet_3(nn.Module):\n",
    "    def __init__(self, num_classes=101, init_weights=True):   \n",
    "        super(AlexNet_3, self).__init__()\n",
    "        self.features = nn.Sequential(  #打包\n",
    "            nn.Conv2d(3, 48, kernel_size=11, stride=4, padding=2),  # input[3, 224, 224]  output[48, 55, 55] 自动舍去小数点后\n",
    "            nn.ReLU(inplace=True), #inplace 可以载入更大模型\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),                  # output[48, 27, 27] kernel_num为原论文一半\n",
    "            nn.Conv2d(48, 128, kernel_size=5, padding=2),           # output[128, 27, 27]\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),                  # output[128, 13, 13]\n",
    "            nn.Conv2d(128, 64, kernel_size=3, padding=1),          # output[128, 13, 13]\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),                  # output[128, 6, 6]\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            #全链接\n",
    "            nn.Linear(64 * 6 * 6, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, num_classes),\n",
    "        )\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, start_dim=1) #展平   或者view()\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu') #何教授方法\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)  #正态分布赋值\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "                \n",
    "\n",
    "class AlexNet_4(nn.Module):\n",
    "    def __init__(self, num_classes=101, init_weights=True):   \n",
    "        super(AlexNet_4, self).__init__()\n",
    "        self.features = nn.Sequential(  #打包\n",
    "            nn.Conv2d(3, 48, kernel_size=11, stride=4, padding=2),  # input[3, 224, 224]  output[48, 55, 55] 自动舍去小数点后\n",
    "            nn.ReLU(inplace=True), #inplace 可以载入更大模型\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),                  # output[48, 27, 27] kernel_num为原论文一半\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Conv2d(48, 64, kernel_size=5, padding=2),           # output[64, 27, 27]\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),    \n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),          # output[64, 13, 13]\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),                  # output[64, 6, 6]\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            #全链接\n",
    "            nn.Linear(64 * 6 * 6, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, num_classes),\n",
    "        )\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, start_dim=1) #展平   或者view()\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu') #何教授方法\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)  #正态分布赋值\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "                           \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 加载数据，分割成训练、验证、测试集（保持类别比例）\n",
    "    train_data = Caltech101Dataset(args, split='train')\n",
    "    torch.manual_seed(args.seed)\n",
    "    train_loader = DataLoader(train_data, batch_size=args.batch_size, shuffle=True) # 打乱训练集训练，防过拟合\n",
    "    val_data = Caltech101Dataset(args, split='val')\n",
    "    val_loader = DataLoader(val_data, batch_size=args.batch_size, shuffle=False) \n",
    "    test_data = Caltech101Dataset(args, split='test')\n",
    "    test_loader = DataLoader(test_data, batch_size=args.batch_size, shuffle=False) \n",
    "    print ('Data loaded.')\n",
    "\n",
    "    # 选择模型\n",
    "    model_name = 'AlexNet_' + args.nn\n",
    "    model_name = globals()[model_name]\n",
    "    model = model_name().to(device)\n",
    "    \n",
    "    writer = SummaryWriter(args.tensorboard_dir)\n",
    "    fake_img = torch.randn(20, 3, 224, 224).to(device)\n",
    "    writer.add_graph(model, (Variable(fake_img),), True)\n",
    "        \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min')\n",
    "\n",
    "    # 训练\n",
    "    best_accur = 0\n",
    "    for epoch in range(args.niters):\n",
    "        train_loss = 0.0\n",
    "        for image, true_y in train_loader: \n",
    "            # print (image.size()) \n",
    "            optimizer.zero_grad() \n",
    "            true_y = true_y.to(device)\n",
    "            pred_y = model(image.to(device)).to(device)    # 得到预测值\n",
    "            # print ('true_y', true_y, 'pred_y:',pred_y)\n",
    "            # exit()\n",
    "            loss = criterion(pred_y, true_y)    # 计算两者的平均损失\n",
    "            # 反向传播和优化\n",
    "            loss.backward()\n",
    "            optimizer.step() \n",
    "            train_loss += loss.item() * image.size(0) # image.size(0) = batch_size, 将每batch的平均损失变成累计损失\n",
    "        train_loss = train_loss / len(train_loader.dataset)     \n",
    "        scheduler.step(loss)\n",
    "      \n",
    "        # 验证\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0.0\n",
    "            correct = 0\n",
    "            correct_top5 = 0\n",
    "            total = 0\n",
    "            for image, true_y in val_loader: \n",
    "                pred_y = model(image.to(device)).to(device)\n",
    "                true_y = true_y.to(device)\n",
    "                loss = criterion(pred_y, true_y).to(device) \n",
    "                val_loss += loss.item() * image.size(0) \n",
    "                total += image.size(0)\n",
    "                # print ('\\n\\n', pred_y, torch.argmax(pred_y, dim=1))\n",
    "                correct += (true_y == torch.argmax(pred_y, dim=1)).sum().item()\n",
    "                top5_pred_y = torch.topk(pred_y, k=5, dim=1).indices\n",
    "                correct_top5 += (top5_pred_y == true_y.unsqueeze(dim=1)).any(dim=1).sum().item()\n",
    "            val_loss = val_loss / len(val_loader.dataset)\n",
    "            val_accur = correct / total\n",
    "            val_accur_top5 = correct_top5 / total\n",
    "            \n",
    "            if val_accur > best_accur:\n",
    "                best_accur = val_accur\n",
    "                torch.save(model, args.model_dir)\n",
    "\n",
    "        print('Epoch:  {} \\tTrain Loss: {:.6f} \\tValidation Loss: {:.6f} \\tValidation Top1 Accuracy: {:.2%} \\nValidation Top5 Accuracy: {:.2%}'\n",
    "            .format(epoch + 1, train_loss, val_loss, val_accur, val_accur_top5))\n",
    "            \n",
    "        # 训练过程参数存进tensorboard\n",
    "        writer.add_scalar('train_loss', train_loss, epoch)\n",
    "        writer.add_scalar('val_accuracy', val_accur, epoch)\n",
    "        writer.add_scalar('val_top5_accuracy', val_accur_top5, epoch)\n",
    "        \n",
    "    writer.close()\n",
    "    print ('Save tensornoard.')       \n",
    "    \n",
    "    \n",
    "    # 测试\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0.0\n",
    "        correct = 0\n",
    "        correct_top5 = 0\n",
    "        total = 0\n",
    "        for image, true_y in test_loader: \n",
    "            pred_y = model(image.to(device)).to(device)\n",
    "            true_y = true_y.to(device)\n",
    "            loss = criterion(pred_y, true_y).to(device) \n",
    "            test_loss += loss.item() * image.size(0) \n",
    "            total += image.size(0)\n",
    "            # print ('\\n\\n', pred_y, torch.argmax(pred_y, dim=1))\n",
    "            correct += (true_y == torch.argmax(pred_y, dim=1)).sum().item()\n",
    "            top5_pred_y = torch.topk(pred_y, k=5, dim=1).indices\n",
    "            correct_top5 += (top5_pred_y == true_y.unsqueeze(dim=1)).any(dim=1).sum().item()\n",
    "        test_loss = test_loss / len(test_loader.dataset)\n",
    "        test_accur = correct / total\n",
    "        test_accur_top5 = correct_top5 / total\n",
    "        \n",
    "    print ('Test Loss: {:.6f} \\tTesting Accuracy: {:.2%} \\tTesting Top5 Accuracy: {:.2%}'\n",
    "           .format(test_loss, test_accur, test_accur_top5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "783ea93b-1ee7-44f3-bfa9-f5b037293f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Starting TensorBoard on port 8000 (pid 16216, Use \"!kill 16216\" to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe id=\"tensorboard-frame-2c2031c431182c59\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "        </iframe>\n",
       "        <script>\n",
       "            (function() {\n",
       "            const frame = document.getElementById(\"tensorboard-frame-2c2031c431182c59\");\n",
       "            const url = new URL(\"/c4f2050c-9115-43bb-8dd6-a1116f5c19a8/proxy/8000/\", window.location);\n",
       "            const port = 0;\n",
       "            if (port) {\n",
       "                url.port = port;\n",
       "            }\n",
       "            frame.src = url;\n",
       "            })();\n",
       "        </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext ma_tensorboard\n",
    "%ma_tensorboard  --logdir './runs' --port 8000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-1.4",
   "language": "python",
   "name": "pytorch-1.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
